{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "import json\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "os.chdir(\"C:/Users/Zber/Documents/Dev_program/OpenRadar\")\n",
    "from FER.utils import MapRecord\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Anger_13_azi.npy, mean: -inf\n",
      "name: Anger_23_azi.npy, mean: -inf\n",
      "name: Anger_23_ele.npy, mean: -inf\n",
      "name: Anger_29_azi.npy, mean: -inf\n",
      "name: Anger_29_ele.npy, mean: -inf\n",
      "name: Anger_7_azi.npy, mean: -inf\n",
      "name: Disgust_14_azi.npy, mean: -inf\n",
      "name: Disgust_14_ele.npy, mean: -inf\n",
      "name: Disgust_15_azi.npy, mean: -inf\n",
      "name: Disgust_15_ele.npy, mean: -inf\n",
      "name: Disgust_19_azi.npy, mean: -inf\n",
      "name: Disgust_19_ele.npy, mean: -inf\n",
      "name: Disgust_7_azi.npy, mean: -inf\n",
      "name: Disgust_7_ele.npy, mean: -inf\n",
      "name: Fear_15_azi.npy, mean: -inf\n",
      "name: Fear_15_ele.npy, mean: -inf\n",
      "name: Fear_19_azi.npy, mean: -inf\n",
      "name: Fear_19_ele.npy, mean: -inf\n",
      "name: Fear_20_azi.npy, mean: -inf\n",
      "name: Fear_20_ele.npy, mean: -inf\n",
      "name: Fear_25_azi.npy, mean: -inf\n",
      "name: Fear_25_ele.npy, mean: -inf\n",
      "name: Fear_26_azi.npy, mean: -inf\n",
      "name: Fear_26_ele.npy, mean: -inf\n",
      "name: Fear_29_azi.npy, mean: -inf\n",
      "name: Fear_29_ele.npy, mean: -inf\n",
      "name: Fear_3_azi.npy, mean: -inf\n",
      "name: Fear_3_ele.npy, mean: -inf\n",
      "name: Fear_5_azi.npy, mean: -inf\n",
      "name: Fear_5_ele.npy, mean: -inf\n",
      "name: Fear_9_azi.npy, mean: -inf\n",
      "name: Fear_9_ele.npy, mean: -inf\n",
      "name: Joy_10_azi.npy, mean: -inf\n",
      "name: Joy_10_ele.npy, mean: -inf\n",
      "name: Joy_11_azi.npy, mean: -inf\n",
      "name: Joy_11_ele.npy, mean: -inf\n",
      "name: Joy_15_azi.npy, mean: -inf\n",
      "name: Joy_15_ele.npy, mean: -inf\n",
      "name: Joy_4_azi.npy, mean: -inf\n",
      "name: Joy_4_ele.npy, mean: -inf\n",
      "name: Joy_5_azi.npy, mean: -inf\n",
      "name: Joy_5_ele.npy, mean: -inf\n",
      "name: Neutral_19_azi.npy, mean: -inf\n",
      "name: Neutral_19_ele.npy, mean: -inf\n",
      "name: Neutral_27_azi.npy, mean: -inf\n",
      "name: Neutral_27_ele.npy, mean: -inf\n",
      "name: Neutral_29_azi.npy, mean: -inf\n",
      "name: Neutral_5_azi.npy, mean: -inf\n",
      "name: Neutral_5_ele.npy, mean: -inf\n",
      "name: Sadness_13_azi.npy, mean: -inf\n",
      "name: Sadness_13_ele.npy, mean: -inf\n",
      "name: Sadness_23_azi.npy, mean: -inf\n",
      "name: Sadness_23_ele.npy, mean: -inf\n",
      "name: Sadness_29_azi.npy, mean: -inf\n",
      "name: Sadness_29_ele.npy, mean: -inf\n",
      "name: Surprise_11_azi.npy, mean: -inf\n",
      "name: Surprise_11_ele.npy, mean: -inf\n",
      "name: Surprise_15_azi.npy, mean: -inf\n",
      "name: Surprise_15_ele.npy, mean: -inf\n",
      "name: Surprise_16_azi.npy, mean: -inf\n",
      "name: Surprise_16_ele.npy, mean: -inf\n",
      "name: Surprise_18_azi.npy, mean: -inf\n",
      "name: Surprise_18_ele.npy, mean: -inf\n",
      "name: Surprise_19_azi.npy, mean: -inf\n",
      "name: Surprise_19_ele.npy, mean: -inf\n",
      "name: Surprise_21_azi.npy, mean: -inf\n",
      "name: Surprise_21_ele.npy, mean: -inf\n",
      "name: Surprise_26_azi.npy, mean: -inf\n",
      "name: Surprise_26_ele.npy, mean: -inf\n",
      "name: Surprise_2_azi.npy, mean: -inf\n"
     ]
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\\\\S5\"\n",
    "exp_list = []\n",
    "mm = 0\n",
    "for file in os.listdir(path):\n",
    "    data_path = os.path.join(path, file)\n",
    "    data = np.load(data_path)\n",
    "    mean = np.mean(data)\n",
    "    if mean == np.NINF:\n",
    "        print(\"name: {}, mean: {}\".format(file, mean))\n",
    "        exp_list.append(file[:-8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anger_13', 'Anger_23', 'Anger_23', 'Anger_29', 'Anger_29', 'Anger_7', 'Disgust_14', 'Disgust_14', 'Disgust_15', 'Disgust_15', 'Disgust_19', 'Disgust_19', 'Disgust_7', 'Disgust_7', 'Fear_15', 'Fear_15', 'Fear_19', 'Fear_19', 'Fear_20', 'Fear_20', 'Fear_25', 'Fear_25', 'Fear_26', 'Fear_26', 'Fear_29', 'Fear_29', 'Fear_3', 'Fear_3', 'Fear_5', 'Fear_5', 'Fear_9', 'Fear_9', 'Joy_10', 'Joy_10', 'Joy_11', 'Joy_11', 'Joy_15', 'Joy_15', 'Joy_4', 'Joy_4', 'Joy_5', 'Joy_5', 'Neutral_19', 'Neutral_19', 'Neutral_27', 'Neutral_27', 'Neutral_29', 'Neutral_5', 'Neutral_5', 'Sadness_13', 'Sadness_13', 'Sadness_23', 'Sadness_23', 'Sadness_29', 'Sadness_29', 'Surprise_11', 'Surprise_11', 'Surprise_15', 'Surprise_15', 'Surprise_16', 'Surprise_16', 'Surprise_18', 'Surprise_18', 'Surprise_19', 'Surprise_19', 'Surprise_21', 'Surprise_21', 'Surprise_26', 'Surprise_26', 'Surprise_2']\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(exp_list)\n",
    "print(len(exp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\\\\heatmap_annotation_full_test.txt\"\n",
    "new_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\\\\heatmap_annotation_full_test_new.txt\"\n",
    "og = open(og_path, 'r')\n",
    "new = open(new_path, 'w')\n",
    "\n",
    "def check_name(name):\n",
    "    for exp in exp_list:\n",
    "        if (\"S5/\"+exp) in name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "for l in og:\n",
    "    if check_name(l):\n",
    "        new.write(l)\n",
    "og.close()\n",
    "new.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def annotation_update(record_list, width=100, total_frame=300):\n",
    "    for record in record_list:\n",
    "        if record.num_frames < width:\n",
    "            pad = (width - record.num_frames)//2\n",
    "            if record.onset < pad:\n",
    "                record.peak += pad*2\n",
    "\n",
    "            elif (total_frame - record.peak) < pad:\n",
    "                record.onset -= pad*2\n",
    "            else:\n",
    "                record.onset -= pad\n",
    "                record.peak += pad\n",
    "        else:\n",
    "            pad = record.num_frames - width\n",
    "            record.peak -= pad\n",
    "\n",
    "        record.path = record.path.replace(\"Raw_0.bin\",\"{}.npy\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "        if record.num_frames != 100:\n",
    "            record.peak += 1\n",
    "        assert record.num_frames == 100, 'the num of frames must equal to 100!'\n",
    "    return record_list\n",
    "\n",
    "\n",
    "def annotation_attention(record_list, width=30):\n",
    "    for record in record_list:\n",
    "        record.onset = math.floor(record.onset * 3 / 10)\n",
    "        record.peak = record.onset + width - 1\n",
    "        record.path = record.relative_path.replace(\"_{}.npy\",\"\")\n",
    "    return record_list\n",
    "\n",
    "\n",
    "def annotation_append():\n",
    "    str_arr = []\n",
    "    str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "    npy_path = \"{}_{}\"\n",
    "    emotion = 'Neutral'\n",
    "    subs = ['S0', 'S1', 'S2', 'S3', 'S4', 'S5']\n",
    "\n",
    "    for sub in subs:\n",
    "        for i in range(0,30):\n",
    "            path = (os.path.join(sub, npy_path.format(emotion, i,)) + '_{}.npy').replace(\"\\\\\", \"/\")\n",
    "            label = \"0\"\n",
    "            onset = 51\n",
    "            peak = 150\n",
    "            offset = -1\n",
    "            e1 = 0\n",
    "            e2 = 0\n",
    "            e3 = 0\n",
    "            str_arr.append(str_format.format(path, label, onset, peak, offset, e1, e2 , e3))\n",
    "    return str_arr\n",
    "\n",
    "\n",
    "def data_split(record_list):\n",
    "    labels = [r.label for r in record_list]\n",
    "    train, test = train_test_split(record_list, test_size=0.2, random_state=25, stratify=labels)\n",
    "    return train, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Surprise_11_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Anger_7_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Anger_13_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Joy_4_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Fear_25_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Surprise_26_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Surprise_19_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Neutral_29_{}.npy\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train.txt\"\n",
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "ele = [-np.inf]\n",
    "\n",
    "for record in record_list:\n",
    "    \n",
    "    npy_path_ele = record.path.format('ele')\n",
    "    npy_path_azi = record.path.format('azi')\n",
    "\n",
    "    ele = np.load(npy_path_ele).flatten()\n",
    "    azi = np.load(npy_path_azi).flatten()\n",
    "\n",
    "    ele = np.mean(ele)\n",
    "    azi = np.mean(azi)\n",
    "\n",
    "    if ele == np.NINF or azi == np.NINF:\n",
    "        print(record.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\n"
     ]
    }
   ],
   "source": [
    "print(np.NINF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Surprise_11_ele.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Joy_4_ele.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Fear_25_ele.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Surprise_26_ele.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Surprise_19_ele.npy\n",
      "Mean : -inf\n",
      "STD : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zber\\anaconda3\\envs\\Emo\\lib\\site-packages\\numpy\\core\\_methods.py:230: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train.txt\"\n",
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "ele = [-np.inf]\n",
    "\n",
    "for record in record_list:\n",
    "    \n",
    "    npy_path = record.path.format('ele')\n",
    "    d = np.load(npy_path).flatten()\n",
    "    mask = np.isin(d, ele)\n",
    "    if len(d[mask]) >0:\n",
    "        print(npy_path)\n",
    "    arr.append(d)\n",
    "\n",
    "arr = np.concatenate(arr, axis=0)\n",
    "\n",
    "mean = np.mean(arr)\n",
    "std = np.std(arr)\n",
    "print(\"Mean : {}\".format(mean))\n",
    "print(\"STD : {}\".format(std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\\\\heatmap_annotation_train.txt\"\n",
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "train = []\n",
    "\n",
    "ele = [-np.inf, np.inf, 0]\n",
    "\n",
    "for record in record_list:\n",
    "    \n",
    "    npy_path = record.path.format('azi')\n",
    "    d = np.load(npy_path).flatten()\n",
    "    # mask = d > 1000\n",
    "    mask = np.isin(d, ele)\n",
    "    if len(d[mask]) >0:\n",
    "        print(npy_path)\n",
    "    # arr.append(d)\n",
    "    else:\n",
    "        train.append(record)\n",
    "\n",
    "# arr = np.concatenate(arr, axis=0)\n",
    "\n",
    "\n",
    "# str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation_train.txt\"), 'a') as f:\n",
    "#     for record in train:\n",
    "#         f.write(str_format.format(record.relative_path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Frames\"\n",
    "# annotaton_path = \"D:\\\\Subjects\\\\annotations_v2.txt\"\n",
    "# annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation.txt\"\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train.txt\"\n",
    "# annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test.txt\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "# new_record_list = annotation_update(record_list)\n",
    "#\n",
    "# # str format: path, label, onset, peak, offset, widthError, heightError, indexError\n",
    "# str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation.txt\"), 'a') as f:\n",
    "#     for record in new_record_list:\n",
    "#         f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(new_record_list)))\n",
    "\n",
    "# train, test = data_split(record_list)\n",
    "\n",
    "# str format: path, label, onset, peak, offset, widthError, heightError, indexError\n",
    "# str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation_train.txt\"), 'a') as f:\n",
    "#     for record in train:\n",
    "#         f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(train)))\n",
    "#\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation_test.txt\"), 'a') as f:\n",
    "#     for record in test:\n",
    "#         f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(test)))\n",
    "\n",
    "\n",
    "# str_arr = annotation_append()\n",
    "# with open(annotaton_path, 'a') as f:\n",
    "#     f.writelines('\\n'.join(str_arr))\n",
    "# print(\"Write {} Records to txt file\".format(len(str_arr)))\n",
    "\n",
    "new_record_list = annotation_attention(record_list)\n",
    "str_format = \"{} {} {} {}\\n\"\n",
    "with open(os.path.join(root_path, \"annotations_att_train.txt\"), 'w') as f:\n",
    "    for record in new_record_list:\n",
    "        f.write(str_format.format(record.path, record.onset, record.peak, record.label))\n",
    "print(\"Write {} Records to txt file\".format(len(new_record_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 979 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train.txt\"\n",
    "new_annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_full_train.txt\"\n",
    "root_path = \"\"\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotation_path)]\n",
    "\n",
    "str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "with open(new_annotation_path, 'w') as f:\n",
    "    for record in record_list:\n",
    "        record.onset = 0\n",
    "        record.peak = 299\n",
    "        f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "print(\"Write {} Records to txt file\".format(len(record_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 252 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test.txt\"\n",
    "new_annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_full_test.txt\"\n",
    "root_path = \"\"\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotation_path)]\n",
    "\n",
    "str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "with open(new_annotation_path, 'w') as f:\n",
    "    for record in record_list:\n",
    "        record.onset = 0\n",
    "        record.peak = 299\n",
    "        f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "print(\"Write {} Records to txt file\".format(len(record_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NST(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(NST, self).__init__()\n",
    "\n",
    "\tdef forward(self, fm_s, fm_t):\n",
    "\t\tfm_s = fm_s.view(fm_s.size(0), fm_s.size(1), -1)\n",
    "\t\tfm_s = F.normalize(fm_s, dim=2)\n",
    "\n",
    "\t\tfm_t = fm_t.view(fm_t.size(0), fm_t.size(1), -1)\n",
    "\t\tfm_t = F.normalize(fm_t, dim=2)\n",
    "\n",
    "\t\tloss = self.poly_kernel(fm_t, fm_t).mean() \\\n",
    "\t\t\t + self.poly_kernel(fm_s, fm_s).mean() \\\n",
    "\t\t\t - 2 * self.poly_kernel(fm_s, fm_t).mean()\n",
    "\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef poly_kernel(self, fm1, fm2):\n",
    "\t\tfm1 = fm1.unsqueeze(1)\n",
    "\t\tfm2 = fm2.unsqueeze(2)\n",
    "\t\tout = (fm1 * fm2).sum(-1).pow(2)\n",
    "\n",
    "\t\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 4, requires_grad=True)\n",
    "model = NST()\n",
    "\n",
    "loss = model(input, target)\n",
    "\n",
    "print(loss.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SP(nn.Module):\n",
    "\t'''\n",
    "\tSimilarity-Preserving Knowledge Distillation\n",
    "\thttps://arxiv.org/pdf/1907.09682.pdf\n",
    "\t'''\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(SP, self).__init__()\n",
    "\n",
    "\tdef forward(self, fm_s, fm_t):\n",
    "\t\tfm_s = fm_s.view(fm_s.size(0), -1)\n",
    "\t\tG_s  = torch.mm(fm_s, fm_s.t())\n",
    "\t\tnorm_G_s = F.normalize(G_s, p=2, dim=1)\n",
    "\n",
    "\t\tfm_t = fm_t.view(fm_t.size(0), -1)\n",
    "\t\tG_t  = torch.mm(fm_t, fm_t.t())\n",
    "\t\tnorm_G_t = F.normalize(G_t, p=2, dim=1)\n",
    "\n",
    "\t\tloss = F.mse_loss(norm_G_s, norm_G_t)\n",
    "\n",
    "\t\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 4, requires_grad=True)\n",
    "model = SP()\n",
    "loss = model(input, target)\n",
    "print(loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 3, 7, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 3, 7, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 32, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([16, 1, 3, 7, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 3, 7, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 32, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([1024, 6144])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024])\n",
      "torch.Size([256])\n",
      "torch.Size([7, 256])\n",
      "torch.Size([7])\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../..\")\n",
    "from FER.em_network.models.c3d import C3DFusionBaseline\n",
    "device = 'cuda'\n",
    "m = C3DFusionBaseline(100, 7)\n",
    "i = 0\n",
    "for p in m.parameters():\n",
    "    print(p.size())\n",
    "    i += 1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FER\n",
    "root = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\"\n",
    "path = \"S2/Disgust_0_{}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "35 * 16"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ab7cd34ae6695140d0643b37c767e4110f6b01903d70850293904b8188cf87a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
