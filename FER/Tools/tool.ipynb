{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "import json\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "os.chdir(\"C:/Users/Zber/Documents/Dev_program/OpenRadar\")\n",
    "from FER.utils import MapRecord\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotation_update(record_list, width=100, total_frame=300):\n",
    "    for record in record_list:\n",
    "        # if record.num_frames < width:\n",
    "        #     pad = (width - record.num_frames)//2\n",
    "        #     if record.onset < pad:\n",
    "        #         record.peak += pad*2\n",
    "\n",
    "        #     elif (total_frame - record.peak) < pad:\n",
    "        #         record.onset -= pad*2\n",
    "        #     else:\n",
    "        #         record.onset -= pad\n",
    "        #         record.peak += pad\n",
    "        # else:\n",
    "        #     pad = record.num_frames - width\n",
    "        #     record.peak -= pad\n",
    "\n",
    "        record.path = record.path.replace(\"Raw_0.bin\",\"{}.npy\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "        if record.num_frames != 100:\n",
    "            record.peak += 1\n",
    "        assert record.num_frames == 100, 'the num of frames must equal to 100!'\n",
    "    return record_list\n",
    "\n",
    "\n",
    "def annotation_attention(record_list, width=30):\n",
    "    for record in record_list:\n",
    "        record.onset = math.floor(record.onset * 3 / 10)\n",
    "        record.peak = record.onset + width - 1\n",
    "        record.path = record.relative_path.replace(\"_{}.npy\",\"\")\n",
    "    return record_list\n",
    "\n",
    "\n",
    "def annotation_append(subs=['S6','S7']):\n",
    "    str_arr = []\n",
    "    str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "    npy_path = \"{}_{}\"\n",
    "    emotion = 'Neutral'\n",
    "    # subs = ['S0', 'S1', 'S2', 'S3', 'S4', 'S5']\n",
    "\n",
    "    for sub in subs:\n",
    "        for i in range(0,30):\n",
    "            path = (os.path.join(sub, npy_path.format(emotion, i,)) + '_{}.npy').replace(\"\\\\\", \"/\")\n",
    "            label = \"0\"\n",
    "            onset = 31\n",
    "            peak = 130\n",
    "            offset = -1\n",
    "            e1 = 0\n",
    "            e2 = 0\n",
    "            e3 = 0\n",
    "            str_arr.append(str_format.format(path, label, onset, peak, offset, e1, e2 , e3))\n",
    "    return str_arr\n",
    "\n",
    "\n",
    "def data_split(record_list):\n",
    "    labels = [r.label for r in record_list]\n",
    "    train, test = train_test_split(record_list, test_size=0.2, random_state=25, stratify=labels)\n",
    "    return train, test\n",
    "\n",
    "def hm_2_frame(root_path, hm_path, frame_path):\n",
    "    record_list = [MapRecord(x.strip().split(), root_path) for x in open(hm_path)]\n",
    "\n",
    "    new_record_list = annotation_attention(record_list)\n",
    "    str_format = \"{} {} {} {}\\n\"\n",
    "    with open(frame_path, 'w') as f:\n",
    "        for record in new_record_list:\n",
    "            f.write(str_format.format(record.path, record.onset, record.peak, record.label))\n",
    "    print(\"Write {} Records to txt file\".format(len(new_record_list)))\n",
    "\n",
    "def hm_2_landmark(root_path, hm_path, frame_path):\n",
    "    record_list = [MapRecord(x.strip().split(), root_path) for x in open(hm_path)]\n",
    "\n",
    "    new_record_list = annotation_attention(record_list)\n",
    "    str_format = \"{} {} {} {}\\n\"\n",
    "    with open(frame_path, 'w') as f:\n",
    "        for record in new_record_list:\n",
    "            re_pa = record.path.replace(\"_{}\",\"\")+\".npy\"\n",
    "            f.write(str_format.format(re_pa, record.onset, record.peak, record.label))\n",
    "    print(\"Write {} Records to txt file\".format(len(new_record_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_record_to_file(record_list, file):\n",
    "    str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "    with open(file, 'a') as f:\n",
    "        for record in record_list:\n",
    "            f.write(str_format.format(record.path, record.label, record.onset, record.peak,\n",
    "                    record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "    print(\"Write {} Records to txt file\".format(len(record_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap annotation file to frame annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FER.utils import get_label\n",
    "\n",
    "# loading data configure\n",
    "annotation_save_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\\"\n",
    "str_arr = []\n",
    "# str format: path, label, onset, peak, offset, widthError, heightError, indexError\n",
    "str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "\n",
    "emotion_list = ['Joy', 'Surprise', 'Anger', 'Sadness', 'Fear', 'Disgust']\n",
    "subs = ['W1']\n",
    "adc_path = \"{}_{}\"\n",
    "\n",
    "start_index = 0\n",
    "end_index = 10\n",
    "onset = 41\n",
    "peak = 140\n",
    "\n",
    "for sub in subs:\n",
    "    for e in emotion_list:\n",
    "        for i in range(start_index, end_index):\n",
    "            relative_path = sub + '/' +adc_path.format(e, i))+ '_{}.npy'\n",
    "            out = [onset, peak, -1, 0, 0, 0]\n",
    "            label = get_label(e)\n",
    "            str_arr.append(str_format.format(relative_path, label, *out))\n",
    "\n",
    "with open(os.path.join(annotation_save_path, \"heatmap_annotation_test_wearmask.txt\"), 'a') as f:\n",
    "    f.writelines('\\n'.join(str_arr))\n",
    "print(\"Write {} Records to txt file\".format(len(str_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"\"\n",
    "# new_heatmap = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\annotations_v3.txt\"\n",
    "new_heatmap_ann = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\annotations_S8_new.txt\"\n",
    "\n",
    "train_ann_og = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_new.txt\"\n",
    "train_ann = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_S8.txt\"\n",
    "test_ann = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_S8.txt\"\n",
    "\n",
    "og_train_list = [MapRecord(x.strip().split(), root_path) for x in open(train_ann_og)]\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(new_heatmap_ann)]\n",
    "train_list, test_list = train_test_split(record_list)\n",
    "train_list = og_train_list + train_list\n",
    "import random\n",
    "random.shuffle(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288\n",
      "347\n"
     ]
    }
   ],
   "source": [
    "new_heatmap_ann = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\annotations_S8_new.txt\"\n",
    "\n",
    "train_ann_og = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_new.txt\"\n",
    "test_ann_og = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_new.txt\"\n",
    "\n",
    "og_train_list = [MapRecord(x.strip().split(), root_path) for x in open(train_ann_og)]\n",
    "og_test_list = [MapRecord(x.strip().split(), root_path) for x in open(test_ann_og)]\n",
    "ONSET = 31\n",
    "PEAK = 130\n",
    "for r in og_train_list:\n",
    "    r.onset = ONSET\n",
    "    r.peak = PEAK\n",
    "for r in og_test_list:\n",
    "    r.onset = ONSET\n",
    "    r.peak = PEAK\n",
    "\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(new_heatmap_ann)]\n",
    "train_list, test_list = train_test_split(record_list)\n",
    "train_list = og_train_list + train_list\n",
    "import random\n",
    "random.shuffle(train_list)\n",
    "test_list = og_test_list + test_list\n",
    "print(len(train_list))\n",
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 1288 Records to txt file\n",
      "Write 347 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "train_ann = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_S8_constant.txt\"\n",
    "test_ann = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_S8_constant.txt\"\n",
    "append_record_to_file(train_list, train_ann)\n",
    "append_record_to_file(test_list, test_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 60 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "subs=['S6','S7']\n",
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "new_heatmap = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\annotations_v3.txt\"\n",
    "new_heatmap_ann = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\annotations_S8_new.txt\"\n",
    "record_list = [MapRecord(x.strip().split(), \"\") for x in open(new_heatmap)]\n",
    "ONSET = 31\n",
    "PEAK = 130\n",
    "for r in record_list:\n",
    "    r.onset = ONSET\n",
    "    r.peak = PEAK\n",
    "\n",
    "record_list = annotation_update(record_list)\n",
    "neutral_list = annotation_append(['S6', 'S7'])\n",
    "\n",
    "str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "# with open(new_heatmap_ann, 'w') as f:\n",
    "#     for record in record_list:\n",
    "#         f.write(str_format.format(record.path, record.label, record.onset, record.peak,\n",
    "#                 record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(record_list)))\n",
    "\n",
    "\n",
    "with open(new_heatmap_ann, 'a') as f:\n",
    "    for record in neutral_list:\n",
    "        f.write(record+'\\n')\n",
    "print(\"Write {} Records to txt file\".format(len(neutral_list)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# neutral_list = annotation_append(['S6', 'S7'])\n",
    "# print(len(record_list))\n",
    "# record_list = record_list + neutral_list\n",
    "# print(len(record_list))\n",
    "# train, test = data_split(record_list)\n",
    "# print(len(train))\n",
    "# print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 1216 Records to txt file\n",
      "Write 333 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "root_path = \"\"\n",
    "hm_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_S8_v1.txt\"\n",
    "frame_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Frames\\\\video_annotation_train_S8_v1.txt\"\n",
    "hm_2_frame(root_path, hm_train, frame_train)\n",
    "\n",
    "hm_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_S8_v1.txt\"\n",
    "frame_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Frames\\\\video_annotation_test_S8_v1.txt\"\n",
    "hm_2_frame(root_path, hm_test, frame_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 973 Records to txt file\n",
      "Write 242 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "hm_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_new.txt\"\n",
    "frame_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Frames\\\\video_annotation_train_new.txt\"\n",
    "hm_2_frame(root_path, hm_train, frame_train)\n",
    "\n",
    "hm_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_new.txt\"\n",
    "frame_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Frames\\\\video_annotation_test_new.txt\"\n",
    "hm_2_frame(root_path, hm_test, frame_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 973 Records to txt file\n",
      "Write 242 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "hm_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_new.txt\"\n",
    "landmark_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Landmark\\\\landmark_annotation_train_new.txt\"\n",
    "hm_2_landmark(root_path, hm_train, landmark_train)\n",
    "\n",
    "hm_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_new.txt\"\n",
    "landmark_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Landmark\\\\landmark_annotation_test_new.txt\"\n",
    "hm_2_landmark(root_path, hm_test, landmark_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25060\\2083661374.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mog\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mnew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25060\\2083661374.py\u001b[0m in \u001b[0;36mcheck_name\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheck_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mexp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexp_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"S5/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exp_list' is not defined"
     ]
    }
   ],
   "source": [
    "og_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\\\\heatmap_annotation_full_test.txt\"\n",
    "new_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\\\\heatmap_annotation_full_test_new.txt\"\n",
    "og = open(og_path, 'r')\n",
    "new = open(new_path, 'w')\n",
    "\n",
    "def check_name(name):\n",
    "    for exp in exp_list:\n",
    "        if (\"S5/\"+exp) in name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "for l in og:\n",
    "    if check_name(l):\n",
    "        new.write(l)\n",
    "og.close()\n",
    "new.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S6/Disgust_4_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S6/Anger_5_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S6/Neutral_24_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S6/Anger_22_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S6/Fear_26_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S6/Surprise_5_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S6/Anger_15_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S6/Sadness_17_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S6/Anger_25_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S6/Sadness_22_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S6/Joy_2_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S6/Surprise_28_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S6/Joy_11_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S6/Neutral_11_{}.npy\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_S8.txt\"\n",
    "# annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_S8.txt\"\n",
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "# ele = [-np.inf]\n",
    "\n",
    "for record in record_list:\n",
    "    \n",
    "    npy_path_ele = record.path.format('ele')\n",
    "    npy_path_azi = record.path.format('azi')\n",
    "\n",
    "    ele = np.load(npy_path_ele).flatten()\n",
    "    azi = np.load(npy_path_azi).flatten()\n",
    "\n",
    "    ele = np.mean(ele)\n",
    "    azi = np.mean(azi)\n",
    "\n",
    "    # if ele == np.NINF or ele==np.Inf or azi == np.NINF or azi==np.Inf:\n",
    "    if ele == np.NINF or azi == np.NINF:\n",
    "        print(record.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288\n",
      "S6/Anger_6_{}.npy\n",
      "S6/Disgust_13_{}.npy\n",
      "S6/Sadness_11_{}.npy\n",
      "S6/Joy_1_{}.npy\n",
      "S6/Sadness_24_{}.npy\n",
      "S6/Sadness_4_{}.npy\n",
      "S6/Anger_18_{}.npy\n",
      "S6/Anger_3_{}.npy\n",
      "S6/Neutral_25_{}.npy\n",
      "S6/Anger_11_{}.npy\n",
      "S6/Neutral_1_{}.npy\n",
      "S6/Disgust_1_{}.npy\n",
      "S6/Neutral_3_{}.npy\n",
      "S6/Joy_16_{}.npy\n",
      "S6/Joy_6_{}.npy\n",
      "S6/Joy_7_{}.npy\n",
      "S6/Sadness_6_{}.npy\n",
      "S6/Joy_22_{}.npy\n",
      "S6/Surprise_21_{}.npy\n",
      "S6/Neutral_12_{}.npy\n",
      "S6/Neutral_16_{}.npy\n",
      "S6/Surprise_23_{}.npy\n",
      "S6/Neutral_23_{}.npy\n",
      "S6/Fear_1_{}.npy\n",
      "S6/Neutral_6_{}.npy\n",
      "S6/Sadness_19_{}.npy\n",
      "S6/Joy_4_{}.npy\n",
      "S6/Joy_9_{}.npy\n",
      "S6/Disgust_27_{}.npy\n",
      "S6/Disgust_22_{}.npy\n",
      "S6/Joy_3_{}.npy\n",
      "S6/Anger_1_{}.npy\n",
      "S6/Anger_26_{}.npy\n",
      "S6/Neutral_17_{}.npy\n",
      "S6/Surprise_8_{}.npy\n",
      "S6/Disgust_26_{}.npy\n",
      "S6/Anger_9_{}.npy\n",
      "S6/Disgust_24_{}.npy\n",
      "S6/Surprise_3_{}.npy\n",
      "S6/Surprise_15_{}.npy\n",
      "S6/Anger_29_{}.npy\n",
      "S6/Sadness_29_{}.npy\n",
      "S6/Neutral_18_{}.npy\n",
      "S6/Anger_4_{}.npy\n",
      "S6/Joy_25_{}.npy\n",
      "S6/Sadness_13_{}.npy\n",
      "S6/Surprise_6_{}.npy\n",
      "S6/Disgust_16_{}.npy\n",
      "S6/Neutral_15_{}.npy\n",
      "S6/Surprise_2_{}.npy\n",
      "S6/Neutral_10_{}.npy\n",
      "S6/Neutral_22_{}.npy\n",
      "S6/Anger_2_{}.npy\n",
      "S6/Fear_29_{}.npy\n",
      "S6/Surprise_22_{}.npy\n",
      "S6/Sadness_7_{}.npy\n",
      "S6/Sadness_3_{}.npy\n",
      "S6/Neutral_9_{}.npy\n",
      "S6/Disgust_23_{}.npy\n",
      "S6/Joy_14_{}.npy\n",
      "S6/Sadness_25_{}.npy\n",
      "S6/Disgust_17_{}.npy\n",
      "S6/Neutral_8_{}.npy\n",
      "S6/Neutral_2_{}.npy\n",
      "S6/Fear_18_{}.npy\n",
      "S6/Sadness_16_{}.npy\n",
      "S6/Disgust_29_{}.npy\n",
      "S6/Anger_7_{}.npy\n",
      "S6/Sadness_5_{}.npy\n",
      "S6/Disgust_25_{}.npy\n",
      "S6/Sadness_26_{}.npy\n",
      "S6/Sadness_2_{}.npy\n",
      "Write 1216 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "text_path = \"C:\\\\Users\\\\Zber\\Desktop\\\\invalid_data.txt\"\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_S8.txt\"\n",
    "root_path = \"\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "print(len(record_list))\n",
    "with open(text_path) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "count = 0\n",
    "for l in lines:\n",
    "    l = l[:-1]\n",
    "    for index, r in enumerate(record_list):\n",
    "        if l in r.path:\n",
    "            print(r.path)\n",
    "            record_list.pop(index)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "\n",
    "new_annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_S8_v1.txt\"\n",
    "append_record_to_file(record_list, new_annotation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347\n",
      "Write 333 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "text_path = \"C:\\\\Users\\\\Zber\\Desktop\\\\invalid_data_test.txt\"\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_S8.txt\"\n",
    "root_path = \"\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "print(len(record_list))\n",
    "with open(text_path) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "count = 0\n",
    "for l in lines:\n",
    "    l = l[:-1]\n",
    "    for index, r in enumerate(record_list):\n",
    "        if l in r.path:\n",
    "            # print(r.path)\n",
    "            record_list.pop(index)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "\n",
    "new_annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_S8_v1.txt\"\n",
    "append_record_to_file(record_list, new_annotation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.13816750796464\n",
      "73.92823863686587\n"
     ]
    }
   ],
   "source": [
    "heatmap_path_1 = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\S1\\\\Anger_0_azi.npy\"\n",
    "heatmap_path_2 = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\S6\\\\Anger_0_azi.npy\"\n",
    "h1 = np.load(heatmap_path_1)\n",
    "h2 = np.load(heatmap_path_2)\n",
    " \n",
    "h1_mean = np.mean(h1)\n",
    "h2_mean = np.mean(h2)\n",
    "print(h1_mean)\n",
    "print(h2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"iiii\".index('i'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean : 86.07235512709005\n",
      "STD : 5.921389444342834\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train.txt\"\n",
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "ele = [-np.inf]\n",
    "\n",
    "for record in record_list:\n",
    "    \n",
    "    npy_path = record.path.format('ele')\n",
    "    d = np.load(npy_path).flatten()\n",
    "    mask = np.isin(d, ele)\n",
    "    if len(d[mask]) >0:\n",
    "        print(npy_path)\n",
    "    arr.append(d)\n",
    "\n",
    "arr = np.concatenate(arr, axis=0)\n",
    "\n",
    "mean = np.mean(arr)\n",
    "std = np.std(arr)\n",
    "print(\"Mean : {}\".format(mean))\n",
    "print(\"STD : {}\".format(std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\\\\heatmap_annotation_train.txt\"\n",
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "train = []\n",
    "\n",
    "ele = [-np.inf, np.inf, 0]\n",
    "\n",
    "for record in record_list:\n",
    "    \n",
    "    npy_path = record.path.format('azi')\n",
    "    d = np.load(npy_path).flatten()\n",
    "    # mask = d > 1000\n",
    "    mask = np.isin(d, ele)\n",
    "    if len(d[mask]) >0:\n",
    "        print(npy_path)\n",
    "    # arr.append(d)\n",
    "    else:\n",
    "        train.append(record)\n",
    "\n",
    "# arr = np.concatenate(arr, axis=0)\n",
    "\n",
    "\n",
    "# str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation_train.txt\"), 'a') as f:\n",
    "#     for record in train:\n",
    "#         f.write(str_format.format(record.relative_path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 979 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Frames\"\n",
    "# annotaton_path = \"D:\\\\Subjects\\\\annotations_v2.txt\"\n",
    "# annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation.txt\"\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train.txt\"\n",
    "# annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test.txt\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "# new_record_list = annotation_update(record_list)\n",
    "#\n",
    "# # str format: path, label, onset, peak, offset, widthError, heightError, indexError\n",
    "# str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation.txt\"), 'a') as f:\n",
    "#     for record in new_record_list:\n",
    "#         f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(new_record_list)))\n",
    "\n",
    "# train, test = data_split(record_list)\n",
    "\n",
    "# str format: path, label, onset, peak, offset, widthError, heightError, indexError\n",
    "# str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation_train.txt\"), 'a') as f:\n",
    "#     for record in train:\n",
    "#         f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(train)))\n",
    "#\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation_test.txt\"), 'a') as f:\n",
    "#     for record in test:\n",
    "#         f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(test)))\n",
    "\n",
    "\n",
    "# str_arr = annotation_append()\n",
    "# with open(annotaton_path, 'a') as f:\n",
    "#     f.writelines('\\n'.join(str_arr))\n",
    "# print(\"Write {} Records to txt file\".format(len(str_arr)))\n",
    "\n",
    "new_record_list = annotation_attention(record_list)\n",
    "str_format = \"{} {} {} {}\\n\"\n",
    "with open(os.path.join(root_path, \"annotations_att_train.txt\"), 'w') as f:\n",
    "    for record in new_record_list:\n",
    "        f.write(str_format.format(record.path, record.onset, record.peak, record.label))\n",
    "print(\"Write {} Records to txt file\".format(len(new_record_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 979 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train.txt\"\n",
    "new_annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_full_train.txt\"\n",
    "root_path = \"\"\n",
    "record_list = [MapRecord(x.strip().split(), root_path)\n",
    "               for x in open(annotation_path)]\n",
    "\n",
    "str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "with open(new_annotation_path, 'w') as f:\n",
    "    for record in record_list:\n",
    "        record.onset = 0\n",
    "        record.peak = 299\n",
    "        f.write(str_format.format(record.path, record.label, record.onset, record.peak,\n",
    "                record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "print(\"Write {} Records to txt file\".format(len(record_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 252 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test.txt\"\n",
    "new_annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_full_test.txt\"\n",
    "root_path = \"\"\n",
    "record_list = [MapRecord(x.strip().split(), root_path)\n",
    "               for x in open(annotation_path)]\n",
    "\n",
    "str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "with open(new_annotation_path, 'w') as f:\n",
    "    for record in record_list:\n",
    "        record.onset = 0\n",
    "        record.peak = 299\n",
    "        f.write(str_format.format(record.path, record.label, record.onset, record.peak,\n",
    "                record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "print(\"Write {} Records to txt file\".format(len(record_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NST(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(NST, self).__init__()\n",
    "\n",
    "\tdef forward(self, fm_s, fm_t):\n",
    "\t\tfm_s = fm_s.view(fm_s.size(0), fm_s.size(1), -1)\n",
    "\t\tfm_s = F.normalize(fm_s, dim=2)\n",
    "\n",
    "\t\tfm_t = fm_t.view(fm_t.size(0), fm_t.size(1), -1)\n",
    "\t\tfm_t = F.normalize(fm_t, dim=2)\n",
    "\n",
    "\t\tloss = self.poly_kernel(fm_t, fm_t).mean() \\\n",
    "\t\t\t + self.poly_kernel(fm_s, fm_s).mean() \\\n",
    "\t\t\t - 2 * self.poly_kernel(fm_s, fm_t).mean()\n",
    "\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef poly_kernel(self, fm1, fm2):\n",
    "\t\tfm1 = fm1.unsqueeze(1)\n",
    "\t\tfm2 = fm2.unsqueeze(2)\n",
    "\t\tout = (fm1 * fm2).sum(-1).pow(2)\n",
    "\n",
    "\t\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26720\\947228434.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 4, requires_grad=True)\n",
    "model = NST()\n",
    "\n",
    "loss = model(input, target)\n",
    "\n",
    "print(loss.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SP(nn.Module):\n",
    "\t'''\n",
    "\tSimilarity-Preserving Knowledge Distillation\n",
    "\thttps://arxiv.org/pdf/1907.09682.pdf\n",
    "\t'''\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(SP, self).__init__()\n",
    "\n",
    "\tdef forward(self, fm_s, fm_t):\n",
    "\t\tfm_s = fm_s.view(fm_s.size(0), -1)\n",
    "\t\tG_s  = torch.mm(fm_s, fm_s.t())\n",
    "\t\tnorm_G_s = F.normalize(G_s, p=2, dim=1)\n",
    "\n",
    "\t\tfm_t = fm_t.view(fm_t.size(0), -1)\n",
    "\t\tG_t  = torch.mm(fm_t, fm_t.t())\n",
    "\t\tnorm_G_t = F.normalize(G_t, p=2, dim=1)\n",
    "\n",
    "\t\tloss = F.mse_loss(norm_G_s, norm_G_t)\n",
    "\n",
    "\t\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 4, requires_grad=True)\n",
    "model = SP()\n",
    "loss = model(input, target)\n",
    "print(loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 3, 7, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 3, 7, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 32, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([16, 1, 3, 7, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 3, 7, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 32, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([1024, 6144])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024])\n",
      "torch.Size([256])\n",
      "torch.Size([7, 256])\n",
      "torch.Size([7])\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../..\")\n",
    "from FER.em_network.models.c3d import C3DFusionBaseline\n",
    "device = 'cuda'\n",
    "m = C3DFusionBaseline(100, 7)\n",
    "i = 0\n",
    "for p in m.parameters():\n",
    "    print(p.size())\n",
    "    i += 1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FER\n",
    "root = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\"\n",
    "path = \"S2/Disgust_0_{}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.arange(9.0).reshape((3, 3))\n",
    "x2 = np.arange(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viscm not found, falling back on simple display\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "cm_data = [[0.2081, 0.1663, 0.5292], [0.2116238095, 0.1897809524, 0.5776761905], \n",
    " [0.212252381, 0.2137714286, 0.6269714286], [0.2081, 0.2386, 0.6770857143], \n",
    " [0.1959047619, 0.2644571429, 0.7279], [0.1707285714, 0.2919380952, \n",
    "  0.779247619], [0.1252714286, 0.3242428571, 0.8302714286], \n",
    " [0.0591333333, 0.3598333333, 0.8683333333], [0.0116952381, 0.3875095238, \n",
    "  0.8819571429], [0.0059571429, 0.4086142857, 0.8828428571], \n",
    " [0.0165142857, 0.4266, 0.8786333333], [0.032852381, 0.4430428571, \n",
    "  0.8719571429], [0.0498142857, 0.4585714286, 0.8640571429], \n",
    " [0.0629333333, 0.4736904762, 0.8554380952], [0.0722666667, 0.4886666667, \n",
    "  0.8467], [0.0779428571, 0.5039857143, 0.8383714286], \n",
    " [0.079347619, 0.5200238095, 0.8311809524], [0.0749428571, 0.5375428571, \n",
    "  0.8262714286], [0.0640571429, 0.5569857143, 0.8239571429], \n",
    " [0.0487714286, 0.5772238095, 0.8228285714], [0.0343428571, 0.5965809524, \n",
    "  0.819852381], [0.0265, 0.6137, 0.8135], [0.0238904762, 0.6286619048, \n",
    "  0.8037619048], [0.0230904762, 0.6417857143, 0.7912666667], \n",
    " [0.0227714286, 0.6534857143, 0.7767571429], [0.0266619048, 0.6641952381, \n",
    "  0.7607190476], [0.0383714286, 0.6742714286, 0.743552381], \n",
    " [0.0589714286, 0.6837571429, 0.7253857143], \n",
    " [0.0843, 0.6928333333, 0.7061666667], [0.1132952381, 0.7015, 0.6858571429], \n",
    " [0.1452714286, 0.7097571429, 0.6646285714], [0.1801333333, 0.7176571429, \n",
    "  0.6424333333], [0.2178285714, 0.7250428571, 0.6192619048], \n",
    " [0.2586428571, 0.7317142857, 0.5954285714], [0.3021714286, 0.7376047619, \n",
    "  0.5711857143], [0.3481666667, 0.7424333333, 0.5472666667], \n",
    " [0.3952571429, 0.7459, 0.5244428571], [0.4420095238, 0.7480809524, \n",
    "  0.5033142857], [0.4871238095, 0.7490619048, 0.4839761905], \n",
    " [0.5300285714, 0.7491142857, 0.4661142857], [0.5708571429, 0.7485190476, \n",
    "  0.4493904762], [0.609852381, 0.7473142857, 0.4336857143], \n",
    " [0.6473, 0.7456, 0.4188], [0.6834190476, 0.7434761905, 0.4044333333], \n",
    " [0.7184095238, 0.7411333333, 0.3904761905], \n",
    " [0.7524857143, 0.7384, 0.3768142857], [0.7858428571, 0.7355666667, \n",
    "  0.3632714286], [0.8185047619, 0.7327333333, 0.3497904762], \n",
    " [0.8506571429, 0.7299, 0.3360285714], [0.8824333333, 0.7274333333, 0.3217], \n",
    " [0.9139333333, 0.7257857143, 0.3062761905], [0.9449571429, 0.7261142857, \n",
    "  0.2886428571], [0.9738952381, 0.7313952381, 0.266647619], \n",
    " [0.9937714286, 0.7454571429, 0.240347619], [0.9990428571, 0.7653142857, \n",
    "  0.2164142857], [0.9955333333, 0.7860571429, 0.196652381], \n",
    " [0.988, 0.8066, 0.1793666667], [0.9788571429, 0.8271428571, 0.1633142857], \n",
    " [0.9697, 0.8481380952, 0.147452381], [0.9625857143, 0.8705142857, 0.1309], \n",
    " [0.9588714286, 0.8949, 0.1132428571], [0.9598238095, 0.9218333333, \n",
    "  0.0948380952], [0.9661, 0.9514428571, 0.0755333333], \n",
    " [0.9763, 0.9831, 0.0538]]\n",
    "\n",
    "parula_map = LinearSegmentedColormap.from_list('parula', cm_data)\n",
    "# For use of \"viscm view\"\n",
    "test_cm = parula_map\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    try:\n",
    "        from viscm import viscm\n",
    "        viscm(parula_map)\n",
    "    except ImportError:\n",
    "        print(\"viscm not found, falling back on simple display\")\n",
    "        plt.imshow(np.linspace(0, 100, 256)[None, :], aspect='auto',\n",
    "                   cmap=parula_map)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ab7cd34ae6695140d0643b37c767e4110f6b01903d70850293904b8188cf87a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
