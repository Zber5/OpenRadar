{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "import json\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "os.chdir(\"C:/Users/Zber/Documents/Dev_program/OpenRadar\")\n",
    "from FER.utils import MapRecord\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotation_update(record_list, width=100, total_frame=300):\n",
    "    for record in record_list:\n",
    "        if record.num_frames < width:\n",
    "            pad = (width - record.num_frames)//2\n",
    "            if record.onset < pad:\n",
    "                record.peak += pad*2\n",
    "\n",
    "            elif (total_frame - record.peak) < pad:\n",
    "                record.onset -= pad*2\n",
    "            else:\n",
    "                record.onset -= pad\n",
    "                record.peak += pad\n",
    "        else:\n",
    "            pad = record.num_frames - width\n",
    "            record.peak -= pad\n",
    "\n",
    "        record.path = record.path.replace(\"Raw_0.bin\",\"{}.npy\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "        if record.num_frames != 100:\n",
    "            record.peak += 1\n",
    "        assert record.num_frames == 100, 'the num of frames must equal to 100!'\n",
    "    return record_list\n",
    "\n",
    "\n",
    "def annotation_attention(record_list, width=30):\n",
    "    for record in record_list:\n",
    "        record.onset = math.floor(record.onset * 3 / 10)\n",
    "        record.peak = record.onset + width - 1\n",
    "        record.path = record.relative_path.replace(\"_{}.npy\",\"\")\n",
    "    return record_list\n",
    "\n",
    "\n",
    "def annotation_append():\n",
    "    str_arr = []\n",
    "    str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "    npy_path = \"{}_{}\"\n",
    "    emotion = 'Neutral'\n",
    "    subs = ['S0', 'S1', 'S2', 'S3', 'S4', 'S5']\n",
    "\n",
    "    for sub in subs:\n",
    "        for i in range(0,30):\n",
    "            path = (os.path.join(sub, npy_path.format(emotion, i,)) + '_{}.npy').replace(\"\\\\\", \"/\")\n",
    "            label = \"0\"\n",
    "            onset = 51\n",
    "            peak = 150\n",
    "            offset = -1\n",
    "            e1 = 0\n",
    "            e2 = 0\n",
    "            e3 = 0\n",
    "            str_arr.append(str_format.format(path, label, onset, peak, offset, e1, e2 , e3))\n",
    "    return str_arr\n",
    "\n",
    "\n",
    "def data_split(record_list):\n",
    "    labels = [r.label for r in record_list]\n",
    "    train, test = train_test_split(record_list, test_size=0.2, random_state=25, stratify=labels)\n",
    "    return train, test\n",
    "\n",
    "def hm_2_frame(root_path, hm_path, frame_path):\n",
    "    record_list = [MapRecord(x.strip().split(), root_path) for x in open(hm_path)]\n",
    "\n",
    "    new_record_list = annotation_attention(record_list)\n",
    "    str_format = \"{} {} {} {}\\n\"\n",
    "    with open(frame_path, 'w') as f:\n",
    "        for record in new_record_list:\n",
    "            f.write(str_format.format(record.path, record.onset, record.peak, record.label))\n",
    "    print(\"Write {} Records to txt file\".format(len(new_record_list)))\n",
    "\n",
    "def hm_2_landmark(root_path, hm_path, frame_path):\n",
    "    record_list = [MapRecord(x.strip().split(), root_path) for x in open(hm_path)]\n",
    "\n",
    "    new_record_list = annotation_attention(record_list)\n",
    "    str_format = \"{} {} {} {}\\n\"\n",
    "    with open(frame_path, 'w') as f:\n",
    "        for record in new_record_list:\n",
    "            re_pa = record.path.replace(\"_{}\",\"\")+\".npy\"\n",
    "            f.write(str_format.format(re_pa, record.onset, record.peak, record.label))\n",
    "    print(\"Write {} Records to txt file\".format(len(new_record_list)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap annotation file to frame annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 973 Records to txt file\n",
      "Write 242 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "hm_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_new.txt\"\n",
    "frame_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Frames\\\\video_annotation_train_new.txt\"\n",
    "hm_2_frame(root_path, hm_train, frame_train)\n",
    "\n",
    "hm_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_new.txt\"\n",
    "frame_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Frames\\\\video_annotation_test_new.txt\"\n",
    "hm_2_frame(root_path, hm_test, frame_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 973 Records to txt file\n",
      "Write 242 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "hm_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_new.txt\"\n",
    "landmark_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Landmark\\\\landmark_annotation_train_new.txt\"\n",
    "hm_2_landmark(root_path, hm_train, landmark_train)\n",
    "\n",
    "hm_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_new.txt\"\n",
    "landmark_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Landmark\\\\landmark_annotation_test_new.txt\"\n",
    "hm_2_landmark(root_path, hm_test, landmark_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25060\\2083661374.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mog\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mnew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25060\\2083661374.py\u001b[0m in \u001b[0;36mcheck_name\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheck_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mexp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexp_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"S5/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exp_list' is not defined"
     ]
    }
   ],
   "source": [
    "og_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\\\\heatmap_annotation_full_test.txt\"\n",
    "new_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\\\\heatmap_annotation_full_test_new.txt\"\n",
    "og = open(og_path, 'r')\n",
    "new = open(new_path, 'w')\n",
    "\n",
    "def check_name(name):\n",
    "    for exp in exp_list:\n",
    "        if (\"S5/\"+exp) in name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "for l in og:\n",
    "    if check_name(l):\n",
    "        new.write(l)\n",
    "og.close()\n",
    "new.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Surprise_11_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Anger_7_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Anger_13_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Joy_4_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Fear_25_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Surprise_26_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Surprise_19_{}.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Neutral_29_{}.npy\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train.txt\"\n",
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "ele = [-np.inf]\n",
    "\n",
    "for record in record_list:\n",
    "    \n",
    "    npy_path_ele = record.path.format('ele')\n",
    "    npy_path_azi = record.path.format('azi')\n",
    "\n",
    "    ele = np.load(npy_path_ele).flatten()\n",
    "    azi = np.load(npy_path_azi).flatten()\n",
    "\n",
    "    ele = np.mean(ele)\n",
    "    azi = np.mean(azi)\n",
    "\n",
    "    if ele == np.NINF or azi == np.NINF:\n",
    "        print(record.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\n"
     ]
    }
   ],
   "source": [
    "print(np.NINF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Surprise_11_ele.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Joy_4_ele.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Fear_25_ele.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Surprise_26_ele.npy\n",
      "C:\\Users\\Zber\\Desktop\\Subjects_Heatmap\\S5/Surprise_19_ele.npy\n",
      "Mean : -inf\n",
      "STD : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zber\\anaconda3\\envs\\Emo\\lib\\site-packages\\numpy\\core\\_methods.py:230: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train.txt\"\n",
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "ele = [-np.inf]\n",
    "\n",
    "for record in record_list:\n",
    "    \n",
    "    npy_path = record.path.format('ele')\n",
    "    d = np.load(npy_path).flatten()\n",
    "    mask = np.isin(d, ele)\n",
    "    if len(d[mask]) >0:\n",
    "        print(npy_path)\n",
    "    arr.append(d)\n",
    "\n",
    "arr = np.concatenate(arr, axis=0)\n",
    "\n",
    "mean = np.mean(arr)\n",
    "std = np.std(arr)\n",
    "print(\"Mean : {}\".format(mean))\n",
    "print(\"STD : {}\".format(std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\\\\heatmap_annotation_train.txt\"\n",
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "train = []\n",
    "\n",
    "ele = [-np.inf, np.inf, 0]\n",
    "\n",
    "for record in record_list:\n",
    "    \n",
    "    npy_path = record.path.format('azi')\n",
    "    d = np.load(npy_path).flatten()\n",
    "    # mask = d > 1000\n",
    "    mask = np.isin(d, ele)\n",
    "    if len(d[mask]) >0:\n",
    "        print(npy_path)\n",
    "    # arr.append(d)\n",
    "    else:\n",
    "        train.append(record)\n",
    "\n",
    "# arr = np.concatenate(arr, axis=0)\n",
    "\n",
    "\n",
    "# str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation_train.txt\"), 'a') as f:\n",
    "#     for record in train:\n",
    "#         f.write(str_format.format(record.relative_path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Frames\"\n",
    "# annotaton_path = \"D:\\\\Subjects\\\\annotations_v2.txt\"\n",
    "# annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation.txt\"\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train.txt\"\n",
    "# annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test.txt\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "# new_record_list = annotation_update(record_list)\n",
    "#\n",
    "# # str format: path, label, onset, peak, offset, widthError, heightError, indexError\n",
    "# str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation.txt\"), 'a') as f:\n",
    "#     for record in new_record_list:\n",
    "#         f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(new_record_list)))\n",
    "\n",
    "# train, test = data_split(record_list)\n",
    "\n",
    "# str format: path, label, onset, peak, offset, widthError, heightError, indexError\n",
    "# str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation_train.txt\"), 'a') as f:\n",
    "#     for record in train:\n",
    "#         f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(train)))\n",
    "#\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation_test.txt\"), 'a') as f:\n",
    "#     for record in test:\n",
    "#         f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(test)))\n",
    "\n",
    "\n",
    "# str_arr = annotation_append()\n",
    "# with open(annotaton_path, 'a') as f:\n",
    "#     f.writelines('\\n'.join(str_arr))\n",
    "# print(\"Write {} Records to txt file\".format(len(str_arr)))\n",
    "\n",
    "new_record_list = annotation_attention(record_list)\n",
    "str_format = \"{} {} {} {}\\n\"\n",
    "with open(os.path.join(root_path, \"annotations_att_train.txt\"), 'w') as f:\n",
    "    for record in new_record_list:\n",
    "        f.write(str_format.format(record.path, record.onset, record.peak, record.label))\n",
    "print(\"Write {} Records to txt file\".format(len(new_record_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 979 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train.txt\"\n",
    "new_annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_full_train.txt\"\n",
    "root_path = \"\"\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotation_path)]\n",
    "\n",
    "str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "with open(new_annotation_path, 'w') as f:\n",
    "    for record in record_list:\n",
    "        record.onset = 0\n",
    "        record.peak = 299\n",
    "        f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "print(\"Write {} Records to txt file\".format(len(record_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 252 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test.txt\"\n",
    "new_annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_full_test.txt\"\n",
    "root_path = \"\"\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotation_path)]\n",
    "\n",
    "str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "with open(new_annotation_path, 'w') as f:\n",
    "    for record in record_list:\n",
    "        record.onset = 0\n",
    "        record.peak = 299\n",
    "        f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "print(\"Write {} Records to txt file\".format(len(record_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NST(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(NST, self).__init__()\n",
    "\n",
    "\tdef forward(self, fm_s, fm_t):\n",
    "\t\tfm_s = fm_s.view(fm_s.size(0), fm_s.size(1), -1)\n",
    "\t\tfm_s = F.normalize(fm_s, dim=2)\n",
    "\n",
    "\t\tfm_t = fm_t.view(fm_t.size(0), fm_t.size(1), -1)\n",
    "\t\tfm_t = F.normalize(fm_t, dim=2)\n",
    "\n",
    "\t\tloss = self.poly_kernel(fm_t, fm_t).mean() \\\n",
    "\t\t\t + self.poly_kernel(fm_s, fm_s).mean() \\\n",
    "\t\t\t - 2 * self.poly_kernel(fm_s, fm_t).mean()\n",
    "\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef poly_kernel(self, fm1, fm2):\n",
    "\t\tfm1 = fm1.unsqueeze(1)\n",
    "\t\tfm2 = fm2.unsqueeze(2)\n",
    "\t\tout = (fm1 * fm2).sum(-1).pow(2)\n",
    "\n",
    "\t\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 4, requires_grad=True)\n",
    "model = NST()\n",
    "\n",
    "loss = model(input, target)\n",
    "\n",
    "print(loss.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SP(nn.Module):\n",
    "\t'''\n",
    "\tSimilarity-Preserving Knowledge Distillation\n",
    "\thttps://arxiv.org/pdf/1907.09682.pdf\n",
    "\t'''\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(SP, self).__init__()\n",
    "\n",
    "\tdef forward(self, fm_s, fm_t):\n",
    "\t\tfm_s = fm_s.view(fm_s.size(0), -1)\n",
    "\t\tG_s  = torch.mm(fm_s, fm_s.t())\n",
    "\t\tnorm_G_s = F.normalize(G_s, p=2, dim=1)\n",
    "\n",
    "\t\tfm_t = fm_t.view(fm_t.size(0), -1)\n",
    "\t\tG_t  = torch.mm(fm_t, fm_t.t())\n",
    "\t\tnorm_G_t = F.normalize(G_t, p=2, dim=1)\n",
    "\n",
    "\t\tloss = F.mse_loss(norm_G_s, norm_G_t)\n",
    "\n",
    "\t\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 4, requires_grad=True)\n",
    "model = SP()\n",
    "loss = model(input, target)\n",
    "print(loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 3, 7, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 3, 7, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 32, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([16, 1, 3, 7, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 3, 7, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 32, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 7, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([1024, 6144])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024])\n",
      "torch.Size([256])\n",
      "torch.Size([7, 256])\n",
      "torch.Size([7])\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../..\")\n",
    "from FER.em_network.models.c3d import C3DFusionBaseline\n",
    "device = 'cuda'\n",
    "m = C3DFusionBaseline(100, 7)\n",
    "i = 0\n",
    "for p in m.parameters():\n",
    "    print(p.size())\n",
    "    i += 1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FER\n",
    "root = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\"\n",
    "path = \"S2/Disgust_0_{}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "35 * 16"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ab7cd34ae6695140d0643b37c767e4110f6b01903d70850293904b8188cf87a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
