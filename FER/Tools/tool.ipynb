{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "import json\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "os.chdir(\"C:/Users/Zber/Documents/Dev_program/OpenRadar\")\n",
    "from FER.utils import MapRecord\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "res_path = \"C:/Users/Zber/Documents/Dev_program/OpenRadar/FER/results\"\n",
    "pca = PCA(n_components=2)\n",
    "kd_path = os.path.join(res_path, 'Supervision_SUM_image2D_KD_20220710-200042')\n",
    "kd_dist = []\n",
    "kd_smap= np.load(os.path.join(kd_path,'smap_{}.npy'.format(0)))\n",
    "kd_tmap= np.load(os.path.join(kd_path,'tmap_{}.npy'.format(0)))\n",
    "kd_tmap = kd_tmap.reshape((242, 30,512,7,7))\n",
    "kd_tmap = np.apply_over_axes(np.mean, kd_tmap, [1,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_tmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 512)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(kd_tmap).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 4096)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kd_smap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotation_update(record_list, width=100, total_frame=300):\n",
    "    for record in record_list:\n",
    "        # if record.num_frames < width:\n",
    "        #     pad = (width - record.num_frames)//2\n",
    "        #     if record.onset < pad:\n",
    "        #         record.peak += pad*2\n",
    "\n",
    "        #     elif (total_frame - record.peak) < pad:\n",
    "        #         record.onset -= pad*2\n",
    "        #     else:\n",
    "        #         record.onset -= pad\n",
    "        #         record.peak += pad\n",
    "        # else:\n",
    "        #     pad = record.num_frames - width\n",
    "        #     record.peak -= pad\n",
    "\n",
    "        record.path = record.path.replace(\"Raw_0.bin\",\"{}.npy\").replace(\"\\\\\", \"/\")\n",
    "\n",
    "        if record.num_frames != 100:\n",
    "            record.peak += 1\n",
    "        assert record.num_frames == 100, 'the num of frames must equal to 100!'\n",
    "    return record_list\n",
    "\n",
    "\n",
    "def annotation_attention(record_list, width=30):\n",
    "    for record in record_list:\n",
    "        record.onset = math.floor(record.onset * 3 / 10)\n",
    "        record.peak = record.onset + width - 1\n",
    "        record.path = record.relative_path.replace(\"_{}.npy\",\"\")\n",
    "    return record_list\n",
    "\n",
    "\n",
    "def annotation_append(subs=['S6','S7']):\n",
    "    str_arr = []\n",
    "    str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "    npy_path = \"{}_{}\"\n",
    "    emotion = 'Neutral'\n",
    "    # subs = ['S0', 'S1', 'S2', 'S3', 'S4', 'S5']\n",
    "\n",
    "    for sub in subs:\n",
    "        for i in range(0,30):\n",
    "            path = (os.path.join(sub, npy_path.format(emotion, i,)) + '_{}.npy').replace(\"\\\\\", \"/\")\n",
    "            label = \"0\"\n",
    "            onset = 31\n",
    "            peak = 130\n",
    "            offset = -1\n",
    "            e1 = 0\n",
    "            e2 = 0\n",
    "            e3 = 0\n",
    "            str_arr.append(str_format.format(path, label, onset, peak, offset, e1, e2 , e3))\n",
    "    return str_arr\n",
    "\n",
    "\n",
    "def data_split(record_list):\n",
    "    labels = [r.label for r in record_list]\n",
    "    train, test = train_test_split(record_list, test_size=0.2, random_state=25, stratify=labels)\n",
    "    return train, test\n",
    "\n",
    "def hm_2_frame(root_path, hm_path, frame_path):\n",
    "    record_list = [MapRecord(x.strip().split(), root_path) for x in open(hm_path)]\n",
    "\n",
    "    new_record_list = annotation_attention(record_list)\n",
    "    str_format = \"{} {} {} {}\\n\"\n",
    "    with open(frame_path, 'w') as f:\n",
    "        for record in new_record_list:\n",
    "            f.write(str_format.format(record.path, record.onset, record.peak, record.label))\n",
    "    print(\"Write {} Records to txt file\".format(len(new_record_list)))\n",
    "\n",
    "def hm_2_landmark(root_path, hm_path, frame_path):\n",
    "    record_list = [MapRecord(x.strip().split(), root_path) for x in open(hm_path)]\n",
    "\n",
    "    new_record_list = annotation_attention(record_list)\n",
    "    str_format = \"{} {} {} {}\\n\"\n",
    "    with open(frame_path, 'w') as f:\n",
    "        for record in new_record_list:\n",
    "            re_pa = record.path.replace(\"_{}\",\"\")+\".npy\"\n",
    "            f.write(str_format.format(re_pa, record.onset, record.peak, record.label))\n",
    "    print(\"Write {} Records to txt file\".format(len(new_record_list)))\n",
    "\n",
    "def hm_2_landmark_v1(record_list, frame_path):\n",
    "    record_list = record_list\n",
    "\n",
    "    new_record_list = annotation_attention(record_list)\n",
    "    str_format = \"{} {} {} {}\\n\"\n",
    "    with open(frame_path, 'w') as f:\n",
    "        for record in new_record_list:\n",
    "            re_pa = record.path.replace(\"_{}\",\"\")+\".npy\"\n",
    "            f.write(str_format.format(re_pa, record.onset, record.peak, record.label))\n",
    "    print(\"Write {} Records to txt file\".format(len(new_record_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_record_to_file(record_list, file):\n",
    "    str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "    with open(file, 'a') as f:\n",
    "        for record in record_list:\n",
    "            f.write(str_format.format(record.path, record.label, record.onset, record.peak,\n",
    "                    record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "    print(\"Write {} Records to txt file\".format(len(record_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ann_file_heatmap(data):\n",
    "    # data is like subject_folder/emotion_name/index\n",
    "    pass\n",
    "\n",
    "\n",
    "def train_test_split(root_path, ann_full_text_file):\n",
    "    # read full file\n",
    "    record_list = [MapRecord(x.strip().split(), root_path) for x in open(ann_full_text_file)]\n",
    "\n",
    "\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 814 Records to txt file\n",
      "Write 420 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "train_file = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_train_landmark_S5.txt\"\n",
    "train_ld = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Landmark_video\\\\landmark_train_S5.txt\"\n",
    "hm_2_landmark(\"\", train_file, train_ld)\n",
    "\n",
    "\n",
    "test_file = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_test_landmark_S5.txt\"\n",
    "test_ld = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Landmark_video\\\\landmark_test_S5.txt\"\n",
    "hm_2_landmark(\"\", test_file, test_ld)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap annotation file to landmark annotation file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_anno_file = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_full_S8.txt\"\n",
    "root_path = \"\"\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(full_anno_file)]\n",
    "for re in record_list:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap annotation file to frame annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FER.utils import get_label\n",
    "\n",
    "# loading data configure\n",
    "annotation_save_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\\"\n",
    "str_arr = []\n",
    "# str format: path, label, onset, peak, offset, widthError, heightError, indexError\n",
    "str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "\n",
    "emotion_list = ['Joy', 'Surprise', 'Anger', 'Sadness', 'Fear', 'Disgust']\n",
    "subs = ['W1']\n",
    "adc_path = \"{}_{}\"\n",
    "\n",
    "start_index = 0\n",
    "end_index = 10\n",
    "onset = 41\n",
    "peak = 140\n",
    "\n",
    "for sub in subs:\n",
    "    for e in emotion_list:\n",
    "        for i in range(start_index, end_index):\n",
    "            relative_path = sub + '/' +adc_path.format(e, i)+ '_{}.npy'\n",
    "            out = [onset, peak, -1, 0, 0, 0]\n",
    "            label = get_label(e)\n",
    "            str_arr.append(str_format.format(relative_path, label, *out))\n",
    "\n",
    "with open(os.path.join(annotation_save_path, \"heatmap_annotation_test_wearmask.txt\"), 'a') as f:\n",
    "    f.writelines('\\n'.join(str_arr))\n",
    "print(\"Write {} Records to txt file\".format(len(str_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"\"\n",
    "# new_heatmap = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\annotations_v3.txt\"\n",
    "new_heatmap_ann = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\annotations_S8_new.txt\"\n",
    "\n",
    "train_ann_og = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_new.txt\"\n",
    "train_ann = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_S8.txt\"\n",
    "test_ann = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_S8.txt\"\n",
    "\n",
    "og_train_list = [MapRecord(x.strip().split(), root_path) for x in open(train_ann_og)]\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(new_heatmap_ann)]\n",
    "train_list, test_list = train_test_split(record_list)\n",
    "train_list = og_train_list + train_list\n",
    "import random\n",
    "random.shuffle(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288\n",
      "347\n"
     ]
    }
   ],
   "source": [
    "new_heatmap_ann = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\annotations_S8_new.txt\"\n",
    "\n",
    "train_ann_og = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_new.txt\"\n",
    "test_ann_og = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_new.txt\"\n",
    "\n",
    "og_train_list = [MapRecord(x.strip().split(), root_path) for x in open(train_ann_og)]\n",
    "og_test_list = [MapRecord(x.strip().split(), root_path) for x in open(test_ann_og)]\n",
    "ONSET = 31\n",
    "PEAK = 130\n",
    "for r in og_train_list:\n",
    "    r.onset = ONSET\n",
    "    r.peak = PEAK\n",
    "for r in og_test_list:\n",
    "    r.onset = ONSET\n",
    "    r.peak = PEAK\n",
    "\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(new_heatmap_ann)]\n",
    "train_list, test_list = train_test_split(record_list)\n",
    "train_list = og_train_list + train_list\n",
    "import random\n",
    "random.shuffle(train_list)\n",
    "test_list = og_test_list + test_list\n",
    "print(len(train_list))\n",
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 1288 Records to txt file\n",
      "Write 347 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "train_ann = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_S8_constant.txt\"\n",
    "test_ann = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_S8_constant.txt\"\n",
    "append_record_to_file(train_list, train_ann)\n",
    "append_record_to_file(test_list, test_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 60 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "subs=['S6','S7']\n",
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "new_heatmap = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\annotations_v3.txt\"\n",
    "new_heatmap_ann = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\annotations_S8_new.txt\"\n",
    "record_list = [MapRecord(x.strip().split(), \"\") for x in open(new_heatmap)]\n",
    "ONSET = 31\n",
    "PEAK = 130\n",
    "for r in record_list:\n",
    "    r.onset = ONSET\n",
    "    r.peak = PEAK\n",
    "\n",
    "record_list = annotation_update(record_list)\n",
    "neutral_list = annotation_append(['S6', 'S7'])\n",
    "\n",
    "str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "# with open(new_heatmap_ann, 'w') as f:\n",
    "#     for record in record_list:\n",
    "#         f.write(str_format.format(record.path, record.label, record.onset, record.peak,\n",
    "#                 record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(record_list)))\n",
    "\n",
    "\n",
    "with open(new_heatmap_ann, 'a') as f:\n",
    "    for record in neutral_list:\n",
    "        f.write(record+'\\n')\n",
    "print(\"Write {} Records to txt file\".format(len(neutral_list)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# neutral_list = annotation_append(['S6', 'S7'])\n",
    "# print(len(record_list))\n",
    "# record_list = record_list + neutral_list\n",
    "# print(len(record_list))\n",
    "# train, test = data_split(record_list)\n",
    "# print(len(train))\n",
    "# print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 1216 Records to txt file\n",
      "Write 333 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "root_path = \"\"\n",
    "hm_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_S8_v1.txt\"\n",
    "frame_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Frames\\\\video_annotation_train_S8_v1.txt\"\n",
    "hm_2_frame(root_path, hm_train, frame_train)\n",
    "\n",
    "hm_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_S8_v1.txt\"\n",
    "frame_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Frames\\\\video_annotation_test_S8_v1.txt\"\n",
    "hm_2_frame(root_path, hm_test, frame_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 973 Records to txt file\n",
      "Write 242 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "hm_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_new.txt\"\n",
    "frame_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Frames\\\\video_annotation_train_new.txt\"\n",
    "hm_2_frame(root_path, hm_train, frame_train)\n",
    "\n",
    "hm_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_new.txt\"\n",
    "frame_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Frames\\\\video_annotation_test_new.txt\"\n",
    "hm_2_frame(root_path, hm_test, frame_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 973 Records to txt file\n",
      "Write 242 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "hm_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_new.txt\"\n",
    "landmark_train = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Landmark\\\\landmark_annotation_train_new.txt\"\n",
    "hm_2_landmark(root_path, hm_train, landmark_train)\n",
    "\n",
    "hm_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_new.txt\"\n",
    "landmark_test = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Landmark\\\\landmark_annotation_test_new.txt\"\n",
    "hm_2_landmark(root_path, hm_test, landmark_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\\\\heatmap_annotation_full_test.txt\"\n",
    "new_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\\\\heatmap_annotation_full_test_new.txt\"\n",
    "og = open(og_path, 'r')\n",
    "new = open(new_path, 'w')\n",
    "\n",
    "def check_name(name):\n",
    "    for exp in exp_list:\n",
    "        if (\"S5/\"+exp) in name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "for l in og:\n",
    "    if check_name(l):\n",
    "        new.write(l)\n",
    "og.close()\n",
    "new.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "text_path = \"C:\\\\Users\\\\Zber\\Desktop\\\\invalid_data.txt\"\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_test_Pose.txt\"\n",
    "root_path = \"\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "print(len(record_list))\n",
    "with open(text_path) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "count = 0\n",
    "for l in lines:\n",
    "    l = l[:-1]\n",
    "    for index, r in enumerate(record_list):\n",
    "        if l in r.path:\n",
    "            print(r.path)\n",
    "            record_list.pop(index)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "\n",
    "# new_annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train_S8_v1.txt\"\n",
    "# append_record_to_file(record_list, new_annotation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347\n",
      "Write 333 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "text_path = \"C:\\\\Users\\\\Zber\\Desktop\\\\invalid_data_test.txt\"\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_S8.txt\"\n",
    "root_path = \"\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "print(len(record_list))\n",
    "with open(text_path) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "count = 0\n",
    "for l in lines:\n",
    "    l = l[:-1]\n",
    "    for index, r in enumerate(record_list):\n",
    "        if l in r.path:\n",
    "            # print(r.path)\n",
    "            record_list.pop(index)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "\n",
    "new_annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test_S8_v1.txt\"\n",
    "append_record_to_file(record_list, new_annotation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.13816750796464\n",
      "73.92823863686587\n"
     ]
    }
   ],
   "source": [
    "heatmap_path_1 = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\S1\\\\Anger_0_azi.npy\"\n",
    "heatmap_path_2 = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\S6\\\\Anger_0_azi.npy\"\n",
    "h1 = np.load(heatmap_path_1)\n",
    "h2 = np.load(heatmap_path_2)\n",
    " \n",
    "h1_mean = np.mean(h1)\n",
    "h2_mean = np.mean(h2)\n",
    "print(h1_mean)\n",
    "print(h2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"iiii\".index('i'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean : 86.07235512709005\n",
      "STD : 5.921389444342834\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train.txt\"\n",
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "ele = [-np.inf]\n",
    "\n",
    "for record in record_list:\n",
    "    \n",
    "    npy_path = record.path.format('ele')\n",
    "    d = np.load(npy_path).flatten()\n",
    "    mask = np.isin(d, ele)\n",
    "    if len(d[mask]) >0:\n",
    "        print(npy_path)\n",
    "    arr.append(d)\n",
    "\n",
    "arr = np.concatenate(arr, axis=0)\n",
    "\n",
    "mean = np.mean(arr)\n",
    "std = np.std(arr)\n",
    "print(\"Mean : {}\".format(mean))\n",
    "print(\"STD : {}\".format(std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\\\\heatmap_annotation_train.txt\"\n",
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap_Large\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "train = []\n",
    "\n",
    "ele = [-np.inf, np.inf, 0]\n",
    "\n",
    "for record in record_list:\n",
    "    \n",
    "    npy_path = record.path.format('azi')\n",
    "    d = np.load(npy_path).flatten()\n",
    "    # mask = d > 1000\n",
    "    mask = np.isin(d, ele)\n",
    "    if len(d[mask]) >0:\n",
    "        print(npy_path)\n",
    "    # arr.append(d)\n",
    "    else:\n",
    "        train.append(record)\n",
    "\n",
    "# arr = np.concatenate(arr, axis=0)\n",
    "\n",
    "\n",
    "# str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation_train.txt\"), 'a') as f:\n",
    "#     for record in train:\n",
    "#         f.write(str_format.format(record.relative_path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 979 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "root_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Frames\"\n",
    "# annotaton_path = \"D:\\\\Subjects\\\\annotations_v2.txt\"\n",
    "# annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation.txt\"\n",
    "annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train.txt\"\n",
    "# annotaton_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test.txt\"\n",
    "\n",
    "record_list = [MapRecord(x.strip().split(), root_path) for x in open(annotaton_path)]\n",
    "\n",
    "# new_record_list = annotation_update(record_list)\n",
    "#\n",
    "# # str format: path, label, onset, peak, offset, widthError, heightError, indexError\n",
    "# str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation.txt\"), 'a') as f:\n",
    "#     for record in new_record_list:\n",
    "#         f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(new_record_list)))\n",
    "\n",
    "# train, test = data_split(record_list)\n",
    "\n",
    "# str format: path, label, onset, peak, offset, widthError, heightError, indexError\n",
    "# str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation_train.txt\"), 'a') as f:\n",
    "#     for record in train:\n",
    "#         f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(train)))\n",
    "#\n",
    "# with open(os.path.join(root_path, \"heatmap_annotation_test.txt\"), 'a') as f:\n",
    "#     for record in test:\n",
    "#         f.write(str_format.format(record.path, record.label, record.onset, record.peak, record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "# print(\"Write {} Records to txt file\".format(len(test)))\n",
    "\n",
    "\n",
    "# str_arr = annotation_append()\n",
    "# with open(annotaton_path, 'a') as f:\n",
    "#     f.writelines('\\n'.join(str_arr))\n",
    "# print(\"Write {} Records to txt file\".format(len(str_arr)))\n",
    "\n",
    "new_record_list = annotation_attention(record_list)\n",
    "str_format = \"{} {} {} {}\\n\"\n",
    "with open(os.path.join(root_path, \"annotations_att_train.txt\"), 'w') as f:\n",
    "    for record in new_record_list:\n",
    "        f.write(str_format.format(record.path, record.onset, record.peak, record.label))\n",
    "print(\"Write {} Records to txt file\".format(len(new_record_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 979 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_train.txt\"\n",
    "new_annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_full_train.txt\"\n",
    "root_path = \"\"\n",
    "record_list = [MapRecord(x.strip().split(), root_path)\n",
    "               for x in open(annotation_path)]\n",
    "\n",
    "str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "with open(new_annotation_path, 'w') as f:\n",
    "    for record in record_list:\n",
    "        record.onset = 0\n",
    "        record.peak = 299\n",
    "        f.write(str_format.format(record.path, record.label, record.onset, record.peak,\n",
    "                record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "print(\"Write {} Records to txt file\".format(len(record_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 252 Records to txt file\n"
     ]
    }
   ],
   "source": [
    "annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_test.txt\"\n",
    "new_annotation_path = \"C:\\\\Users\\\\Zber\\\\Desktop\\\\Subjects_Heatmap\\\\heatmap_annotation_full_test.txt\"\n",
    "root_path = \"\"\n",
    "record_list = [MapRecord(x.strip().split(), root_path)\n",
    "               for x in open(annotation_path)]\n",
    "\n",
    "str_format = \"{} {} {} {} {} {} {} {}\"\n",
    "with open(new_annotation_path, 'w') as f:\n",
    "    for record in record_list:\n",
    "        record.onset = 0\n",
    "        record.peak = 299\n",
    "        f.write(str_format.format(record.path, record.label, record.onset, record.peak,\n",
    "                record.offset, record.width_err, record.height_err, record.index_err)+'\\n')\n",
    "print(\"Write {} Records to txt file\".format(len(record_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy to subject\n",
    "source_folder = \"D:/Subjects/S0\"\n",
    "\n",
    "# target_folder = \"D:/Subjects/S8\"\n",
    "# start_index = 30\n",
    "# end_index = 60\n",
    "\n",
    "\n",
    "target_folder = \"D:/Subjects/S9\"\n",
    "start_index = 50\n",
    "end_index = 80\n",
    "\n",
    "files = []\n",
    "arr = np.arange(start_index, end_index)\n",
    "for file in os.listdir(source_folder):\n",
    "    if \".svo\" in file:\n",
    "        num = file[file.index(\"_\")+1:file.index(\".\")]\n",
    "        if int(num) in arr:\n",
    "            files.append(file)\n",
    "    else:\n",
    "        ids = [i for i in range(len(file)) if file[i] == \"_\"]\n",
    "        num = file[ids[0]+1:ids[1]]\n",
    "        if int(num) in arr:\n",
    "            files.append(file)\n",
    "\n",
    "\n",
    "import shutil\n",
    "for file in files:\n",
    "    src = os.path.join(source_folder, file)\n",
    "    target_file = file\n",
    "    if \".svo\" in file:\n",
    "        old_num =target_file[target_file.index(\"_\")+1:target_file.index(\".\")]\n",
    "    else:\n",
    "        ids = [i for i in range(len(file)) if file[i] == \"_\"]\n",
    "        old_num =target_file[ids[0]+1:ids[1]]\n",
    "    new_num = int(old_num) - start_index\n",
    "    replace_file = target_file.replace(str(old_num), str(new_num)) \n",
    "    dst = os.path.join(target_folder, replace_file)\n",
    "    print(\"{} --> {}\".format(src, dst))\n",
    "    shutil.copy2(src, dst)\n",
    "\n",
    "\n",
    "\n",
    "    #     ids = [i for i in range(len(file)) if file[i] == \"_\"]\n",
    "    # for id  in range(start_index, end_index):\n",
    "    #     if len(ids) >= 2:\n",
    "    #         if file[ids[0]:ids[1]] == id:\n",
    "    #             print(file)\n",
    "    #     else:\n",
    "    #         if file[ids[0]:] == id:\n",
    "    #             print(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_path = \"C:/Users/Zber/Desktop/Subjects_Landmark/S5/Anger_29.npy\"\n",
    "data = np.load(np_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.85584365, 2.17270638, 2.24000685, 2.11763916, 2.02851648,\n",
       "       2.3239866 , 2.40151275])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "m = np.asarray([5.789, 10.342, 11.321, 11.931, 13.225, 17.231, 18.932])/100\n",
    "d = np.asarray([24.597, 17.519, 15.069, 13.572, 11.871, 10.578, 10.101])\n",
    "std = np.asarray([1.756, 2.060, 3.544, 3.672, 3.863, 4.739, 4.843])/100\n",
    "(m+std)*d\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0210c7e9b9cf9ed8e3f7452f6d428fef60037b48b80a0b353b2536d40dcfcdca"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
